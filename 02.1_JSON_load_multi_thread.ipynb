{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.0-999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.1000-1999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.2000-2999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.3000-3999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.4000-4999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.5000-5999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.6000-6999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.7000-7999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.8000-8999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.9000-9999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.10000-10999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.11000-11999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.12000-12999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.13000-13999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.14000-14999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.15000-15999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.16000-16999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.17000-17999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.18000-18999.json...\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.19000-19999.json...\n",
      "Length of album_data_batch: 66925Length of album_data_batch: 68546\n",
      "Length of track_data_batch: 68546\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.20000-20999.json...\n",
      "\n",
      "Length of track_data_batch: 66925\n",
      "Length of album_data_batch: 69441\n",
      "Length of track_data_batch: 69441\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.21000-21999.json...\n",
      "Length of album_data_batch: 66127\n",
      "Length of track_data_batch: 66127\n",
      "Length of album_data_batch: 67503\n",
      "Length of track_data_batch: 67503\n",
      "Length of album_data_batch: 68101\n",
      "Length of track_data_batch: 68101\n",
      "Length of album_data_batch: 66648\n",
      "Length of track_data_batch: 66648\n",
      "Length of album_data_batch: 67614\n",
      "Length of track_data_batch: 67614\n",
      "Length of album_data_batch: 66656\n",
      "Length of track_data_batch: 66656\n",
      "Length of album_data_batch: 67229\n",
      "Length of track_data_batch: 67229\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.22000-22999.json...\n",
      "Length of album_data_batch: 67185\n",
      "Length of track_data_batch: 67185\n",
      "Length of album_data_batch: 66622\n",
      "Length of track_data_batch: 66622\n",
      "Length of album_data_batch: 66282\n",
      "Length of track_data_batch: 66282\n",
      "Length of album_data_batch: 64939\n",
      "Length of track_data_batch: 64939\n",
      "Length of album_data_batch: 66048\n",
      "Length of track_data_batch: 66048\n",
      "Length of album_data_batch: 65113\n",
      "Length of track_data_batch: 65113\n",
      "Length of album_data_batch: 65749\n",
      "Length of track_data_batch: 65749\n",
      "Length of album_data_batch: 65742\n",
      "Length of track_data_batch: 65742\n",
      "Length of album_data_batch: 63292\n",
      "Length of track_data_batch: 63292\n",
      "Length of album_data_batch: 66542\n",
      "Length of track_data_batch: 66542\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.23000-23999.json...\n",
      "Length of album_data_batch: 67529\n",
      "Length of track_data_batch: 67529\n",
      "Length of album_data_batch: 66512\n",
      "Length of track_data_batch: 66512\n",
      "Length of album_data_batch: 69943\n",
      "Length of track_data_batch: 69943\n",
      "Length of album_data_batch: 67125\n",
      "Length of track_data_batch: 67125\n",
      "Successfully inserted into albums.\n",
      "Successfully inserted into tracks.\n",
      "Processing /Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.24000-24999.json...\n",
      "Length of album_data_batch: 66582\n",
      "Length of track_data_batch: 66582\n",
      "Successfully inserted into albums.\n",
      "Successfully inserted into tracks.\n",
      "Successfully inserted into albums.\n",
      "Successfully inserted into tracks.\n",
      "Successfully inserted into albums.\n",
      "Successfully inserted into tracks.\n",
      "Successfully inserted into albums.\n",
      "Successfully inserted into tracks.\n",
      "Successfully inserted into albums.\n",
      "Successfully inserted into albums.\n",
      "Successfully inserted into tracks.\n",
      "Successfully inserted into albums.\n",
      "Successfully inserted into tracks.\n",
      "Successfully inserted into albums.\n",
      "Successfully inserted into tracks.\n",
      "Successfully inserted into tracks.\n",
      "Number of rows in albums: 76230\n",
      "Number of rows in tracks: 156678\n"
     ]
    }
   ],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import json\n",
    "import sqlite3\n",
    "\n",
    "def connect_db(db_name):\n",
    "    conn = sqlite3.connect(db_name)\n",
    "    return conn\n",
    "\n",
    "def insert_into_playlists(conn, playlist_data_batch):\n",
    "    cur = conn.cursor()\n",
    "    cur.executemany('''\n",
    "        INSERT OR IGNORE INTO playlists (\n",
    "            playlist_id,\n",
    "            p_name, \n",
    "            p_num_tracks, \n",
    "            p_num_albums, \n",
    "            p_num_followers, \n",
    "            p_num_artists, \n",
    "            p_duration_ms, \n",
    "            p_num_edits, \n",
    "            p_modified_at, \n",
    "            p_collaborative\n",
    "        )\n",
    "        VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    ''', playlist_data_batch)\n",
    "    conn.commit()\n",
    "\n",
    "# Similar functions for other tables...\n",
    "\"\"\" def insert_into_tracks(conn, track_data_batch):\n",
    "    cur = conn.cursor()\n",
    "    print(f\"Track Data Batch: {track_data_batch}\")\n",
    "    cur.executemany('''INSERT OR IGNORE INTO tracks (t_uri, t_name, t_duration_ms, artist_name, artist_uri, album_uri) VALUES (?, ?, ?, ?, ?, ?)''', track_data_batch)\n",
    "    conn.commit()\n",
    "\n",
    "def insert_into_albums(conn, album_data_batch):\n",
    "    cur = conn.cursor()\n",
    "    print(f\"Album Data Batch: {album_data_batch}\")\n",
    "    cur.executemany('''INSERT OR IGNORE INTO albums (album_uri, album_name) VALUES (?, ?)''', album_data_batch)\n",
    "    conn.commit() \"\"\"\n",
    "\n",
    "def insert_into_artists(conn, artist_data_batch):\n",
    "    cur = conn.cursor()\n",
    "    cur.executemany('''INSERT OR IGNORE INTO artists (artist_uri, artist_name) VALUES (?, ?)''', artist_data_batch)\n",
    "    conn.commit()\n",
    "\n",
    "def insert_into_playlist_tracks(conn, playlist_track_data_batch):\n",
    "    cur = conn.cursor()\n",
    "    cur.executemany('''INSERT OR IGNORE INTO playlist_tracks (playlist_id, t_uri, position) VALUES (?, ?, ?)''', playlist_track_data_batch)\n",
    "    conn.commit()\n",
    "\n",
    "def insert_into_albums(conn, album_data_batch):\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        cur.executemany('''INSERT OR IGNORE INTO albums (album_uri, album_name) VALUES (?, ?)''', album_data_batch)\n",
    "        conn.commit()\n",
    "        print(\"Successfully inserted into albums.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"SQLite error while inserting into albums: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "def insert_into_tracks(conn, track_data_batch):\n",
    "    cur = conn.cursor()\n",
    "    try:\n",
    "        cur.executemany('''INSERT OR IGNORE INTO tracks (t_uri, t_name, t_duration_ms, artist_name, artist_uri, album_uri) VALUES (?, ?, ?, ?, ?, ?)''', track_data_batch)\n",
    "        conn.commit()\n",
    "        print(\"Successfully inserted into tracks.\")\n",
    "    except sqlite3.Error as e:\n",
    "        print(f\"SQLite error while inserting into tracks: {e}\")\n",
    "        conn.rollback()\n",
    "\n",
    "\n",
    "def process_file(json_file):\n",
    "    playlist_data_batch = []\n",
    "    track_data_batch = []\n",
    "    album_data_batch = []\n",
    "    artist_data_batch = []\n",
    "    playlist_track_data_batch = []\n",
    "\n",
    "    \n",
    "    with open(json_file, 'r') as f:\n",
    "        print(f\"Processing {json_file}...\")\n",
    "        data = json.load(f)\n",
    "\n",
    "    for playlist in data['playlists']:\n",
    "        playlist_data = (\n",
    "            playlist.get('pid'),\n",
    "            playlist.get('name'),\n",
    "            playlist.get('num_tracks'),\n",
    "            playlist.get('num_albums'),\n",
    "            playlist.get('num_followers'),\n",
    "            playlist.get('num_artists'),\n",
    "            playlist.get('duration_ms'),\n",
    "            playlist.get('num_edits'),\n",
    "            playlist.get('modified_at'),\n",
    "            playlist.get('collaborative')\n",
    "        )\n",
    "        playlist_data_batch.append(playlist_data)\n",
    "\n",
    "        for track in playlist['tracks']:\n",
    "            track_data = (\n",
    "                track.get('track_uri'),\n",
    "                track.get('track_name'),\n",
    "                track.get('duration_ms'),\n",
    "                track.get('artist_name'),\n",
    "                track.get('artist_uri'),\n",
    "                track.get('album_uri')\n",
    "            )\n",
    "            track_data_batch.append(track_data)\n",
    "\n",
    "            album_data = (track.get('album_uri'), track.get('album_name'))\n",
    "            album_data_batch.append(album_data)\n",
    "\n",
    "            artist_data = (track.get('artist_uri'), track.get('artist_name'))\n",
    "            artist_data_batch.append(artist_data)\n",
    "\n",
    "            playlist_track_data = (playlist.get('pid'), track.get('track_uri'), track.get('pos'))\n",
    "            playlist_track_data_batch.append(playlist_track_data)\n",
    "\n",
    "    conn = connect_db('playlist_analysis.db')\n",
    "\n",
    "    print(f\"Length of album_data_batch: {len(album_data_batch)}\")\n",
    "    print(f\"Length of track_data_batch: {len(track_data_batch)}\")\n",
    "\n",
    "    \n",
    "    insert_into_playlists(conn, playlist_data_batch)\n",
    "    insert_into_albums(conn, album_data_batch)\n",
    "    insert_into_artists(conn, artist_data_batch)\n",
    "    insert_into_tracks(conn, track_data_batch)\n",
    "    insert_into_playlist_tracks(conn, playlist_track_data_batch)\n",
    "    conn.commit()  \n",
    "\n",
    "def check_data(conn):\n",
    "    cur = conn.cursor()\n",
    "    cur.execute(\"SELECT COUNT(*) FROM albums\")\n",
    "    print(f\"Number of rows in albums: {cur.fetchone()[0]}\")\n",
    "    cur.execute(\"SELECT COUNT(*) FROM tracks\")\n",
    "    print(f\"Number of rows in tracks: {cur.fetchone()[0]}\")\n",
    "\n",
    "def main():\n",
    "    conn = connect_db('playlist_analysis.db')\n",
    "    # Create a list of JSON files\n",
    "    path = '/Users/fried/Documents/DataScience/4season/DSP/Spotify/Datensatz/playlists/mpd.slice.'\n",
    "    json_file_list = [f\"{path}{i * 1000}-{(i + 1) * 1000 - 1}.json\" for i in range(25)]\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        executor.map(process_file, json_file_list)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "    conn = connect_db('playlist_analysis.db')\n",
    "    # Check the data after processing all files\n",
    "    check_data(conn)\n",
    "    conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
